{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c42bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from atae_lstm import *\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6678de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE_PATH = '../data/absa/SemEval14/abas-pytorch/Laptops_Train.xml.seg'\n",
    "TEST_FILE_PATH = '../data/absa/SemEval14/abas-pytorch/Laptops_Test_Gold.xml.seg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63f6329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ad49754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer:  ./output/laptop_tokenizer.dat\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = build_tokenizer(fnames=[TRAIN_FILE_PATH, TEST_FILE_PATH], \n",
    "                            max_seq_len=85,\n",
    "                            dat_fname='./output/laptop_tokenizer.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5924b27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n",
      "2096\n"
     ]
    }
   ],
   "source": [
    "trainset = ABSADataset(TRAIN_FILE_PATH, tokenizer)\n",
    "testset = ABSADataset(TEST_FILE_PATH, tokenizer)\n",
    "\n",
    "print(len(trainset))\n",
    "val_len = int(len(trainset) * 0.1)\n",
    "trainset, valset = random_split(trainset, [len(trainset) - val_len, val_len])\n",
    "print(len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "890850bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1:  [1 2 0 0]\n",
      "x2:  [11 22 33 44]\n",
      "x_batch:  tensor([[ 1,  2,  0,  0],\n",
      "        [11, 22, 33, 44]])\n",
      "embedding:  tensor([[[ 1.0753, -0.1936,  0.2285],\n",
      "         [-1.7786, -0.0876,  0.7390],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.5963,  1.1189, -0.8744],\n",
      "         [ 0.5256,  0.2629, -0.7533],\n",
      "         [-0.6376, -0.9655, -0.8938],\n",
      "         [-0.3643, -1.5764, -0.0581]]], grad_fn=<EmbeddingBackward0>)\n",
      "squeeze embedding:  tensor([[[ 1.0753, -0.1936,  0.2285],\n",
      "         [-1.7786, -0.0876,  0.7390],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.5963,  1.1189, -0.8744],\n",
      "         [ 0.5256,  0.2629, -0.7533],\n",
      "         [-0.6376, -0.9655, -0.8938],\n",
      "         [-0.3643, -1.5764, -0.0581]]], grad_fn=<IndexBackward0>)\n",
      "rnn forward....\n",
      "x raw:  tensor([[[ 1.0753, -0.1936,  0.2285],\n",
      "         [-1.7786, -0.0876,  0.7390],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.5963,  1.1189, -0.8744],\n",
      "         [ 0.5256,  0.2629, -0.7533],\n",
      "         [-0.6376, -0.9655, -0.8938],\n",
      "         [-0.3643, -1.5764, -0.0581]]], grad_fn=<EmbeddingBackward0>)\n",
      "x len:  tensor([2, 4])\n",
      "x_sort_idx:  tensor([1, 0])\n",
      "x_sort:  tensor([[[-0.5963,  1.1189, -0.8744],\n",
      "         [ 0.5256,  0.2629, -0.7533],\n",
      "         [-0.6376, -0.9655, -0.8938],\n",
      "         [-0.3643, -1.5764, -0.0581]],\n",
      "\n",
      "        [[ 1.0753, -0.1936,  0.2285],\n",
      "         [-1.7786, -0.0876,  0.7390],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<IndexBackward0>)\n",
      "x_emb_p:  PackedSequence(data=tensor([[-0.5963,  1.1189, -0.8744],\n",
      "        [ 1.0753, -0.1936,  0.2285],\n",
      "        [ 0.5256,  0.2629, -0.7533],\n",
      "        [-1.7786, -0.0876,  0.7390],\n",
      "        [-0.6376, -0.9655, -0.8938],\n",
      "        [-0.3643, -1.5764, -0.0581]], grad_fn=<PackPaddedSequenceBackward0>), batch_sizes=tensor([2, 2, 1, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "out_pack:  PackedSequence(data=tensor([[-0.1597,  0.0910, -0.0491,  0.1781,  0.0039,  0.0674],\n",
      "        [ 0.0031,  0.0742, -0.0635,  0.0349, -0.0312,  0.0367],\n",
      "        [-0.1917,  0.0829, -0.0973,  0.2614, -0.0844,  0.0359],\n",
      "        [-0.0737,  0.1129,  0.1165, -0.0190,  0.0678,  0.0959],\n",
      "        [-0.1405, -0.0123,  0.0287,  0.1531, -0.1423, -0.0180],\n",
      "        [-0.0872, -0.0558,  0.1599,  0.0192, -0.1092, -0.0349]],\n",
      "       grad_fn=<CatBackward0>), batch_sizes=tensor([2, 2, 1, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "out1:  (tensor([[[-0.1597,  0.0910, -0.0491,  0.1781,  0.0039,  0.0674],\n",
      "         [-0.1917,  0.0829, -0.0973,  0.2614, -0.0844,  0.0359],\n",
      "         [-0.1405, -0.0123,  0.0287,  0.1531, -0.1423, -0.0180],\n",
      "         [-0.0872, -0.0558,  0.1599,  0.0192, -0.1092, -0.0349]],\n",
      "\n",
      "        [[ 0.0031,  0.0742, -0.0635,  0.0349, -0.0312,  0.0367],\n",
      "         [-0.0737,  0.1129,  0.1165, -0.0190,  0.0678,  0.0959],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<TransposeBackward0>), tensor([4, 2]))\n",
      "out2:  tensor([[[-0.1597,  0.0910, -0.0491,  0.1781,  0.0039,  0.0674],\n",
      "         [-0.1917,  0.0829, -0.0973,  0.2614, -0.0844,  0.0359],\n",
      "         [-0.1405, -0.0123,  0.0287,  0.1531, -0.1423, -0.0180],\n",
      "         [-0.0872, -0.0558,  0.1599,  0.0192, -0.1092, -0.0349]],\n",
      "\n",
      "        [[ 0.0031,  0.0742, -0.0635,  0.0349, -0.0312,  0.0367],\n",
      "         [-0.0737,  0.1129,  0.1165, -0.0190,  0.0678,  0.0959],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "out3:  tensor([[[ 0.0031,  0.0742, -0.0635,  0.0349, -0.0312,  0.0367],\n",
      "         [-0.0737,  0.1129,  0.1165, -0.0190,  0.0678,  0.0959],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1597,  0.0910, -0.0491,  0.1781,  0.0039,  0.0674],\n",
      "         [-0.1917,  0.0829, -0.0973,  0.2614, -0.0844,  0.0359],\n",
      "         [-0.1405, -0.0123,  0.0287,  0.1531, -0.1423, -0.0180],\n",
      "         [-0.0872, -0.0558,  0.1599,  0.0192, -0.1092, -0.0349]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "ct:  tensor([[[-0.2334, -0.1539,  0.4150,  0.0434, -0.1907, -0.0815],\n",
      "         [-0.1625,  0.2010,  0.3259, -0.0469,  0.1946,  0.2411]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x1 = [1, 2]\n",
    "x2 = [11, 22, 33, 44]\n",
    "x_len = [2, 4]\n",
    "x_len = torch.tensor(x_len)\n",
    "x1_pad = pad_and_truncate(x1, 4)\n",
    "x2_pad = pad_and_truncate(x2, 4)\n",
    "print('x1: ', x1_pad)\n",
    "print('x2: ', x2_pad)\n",
    "\n",
    "x_batch = np.vstack((x1_pad, x2_pad))\n",
    "x_batch = torch.tensor(x_batch)\n",
    "print('x_batch: ', x_batch)\n",
    "\n",
    "embedding = nn.Embedding(1000, 3, padding_idx=0)\n",
    "x_batch_embd = embedding(x_batch)\n",
    "print('embedding: ', x_batch_embd)\n",
    "\n",
    "squeeze_embedding = SqueezeEmbedding()\n",
    "x_batch_squeeze_embd = squeeze_embedding(x_batch_embd, x_len)\n",
    "print('squeeze embedding: ', x_batch_squeeze_embd)\n",
    "\n",
    "rnn_test = DynamicRNN(3, 6)\n",
    "out, (ht, ct) = rnn_test(x_batch_embd, x_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da56b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
